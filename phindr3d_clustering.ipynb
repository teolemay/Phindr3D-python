{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHINDR3D Results and clustering\n",
    "\n",
    "Visualize Phindr3D results and perform affinity propagation clustering.\n",
    "\n",
    "code marked `EDIT HERE` may be edited as needed to get desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phindr_clustering as clu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.metrics as met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Loading\n",
    "\n",
    "Load saved image feature file and filter as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to csv file: EDIT HERE\n",
    "filename = r'FILE_PATH'\n",
    "\n",
    "#filter out images with \"Not a number\" megavoxel frequencies (happens when no megavoxels found)\n",
    "Filter_NaN = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_feature_data_raw = pd.read_csv(filename, index_col=0) \n",
    "\n",
    "if Filter_NaN:\n",
    "    image_feature_data_raw = image_feature_data_raw.dropna()\n",
    "\n",
    "from IPython.display import display\n",
    "display(image_feature_data_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe as needed:\n",
    "#   to filter the dataframe (e.g. to only select orws with specific range of values):\n",
    "#   set filter_data to True below, change FILTER COLUMN to the desired column, \n",
    "#   change FILTER VALUE to the desired value, and check that the operation (==, >, <, <=, >=) is correct.\n",
    "#   copy and paste the indented filter control lines below to add aditional filtering as needed.\n",
    "filter_data = False\n",
    "\n",
    "#rescale texture features to the range [0, 1]\n",
    "rescale_texture_features = False\n",
    "\n",
    "# choose dataset to use for clustering: EDIT HERE\n",
    "# Choices: \n",
    "# 'MV' -> megavoxel frequencies, \n",
    "# 'text' -> 4 haralick texture features, \n",
    "# 'combined' -> both together\n",
    "datachoice = 'MV'\n",
    "\n",
    "if filter_data:\n",
    "    df = image_feature_data_raw\n",
    "\n",
    "    #filter here \n",
    "    #documentation on how to filter Pandas dataframes can be found at: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc \n",
    "\n",
    "    image_feature_data = df\n",
    "else:\n",
    "    image_feature_data = image_feature_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max scale all data:\n",
    "columns = image_feature_data.columns\n",
    "image_feature_data[columns[4:]] = (image_feature_data[columns[4:]] - image_feature_data[columns[4:]].min())/(image_feature_data[columns[4:]].max()-image_feature_data[columns[4:]].min())\n",
    "image_feature_data[columns[-4:]] = ((image_feature_data[columns[-4:]] - image_feature_data[columns[-4:]].min())/(image_feature_data[columns[-4:]].max()-image_feature_data[columns[-4:]].min()))\n",
    "\n",
    "#get misc values\n",
    "num_images_kept = image_feature_data.shape[0]\n",
    "print(f'\\nNumber of images: {num_images_kept}\\n')\n",
    "imageIDs = np.array(image_feature_data['ImageID'], dtype='object')\n",
    "uniqueIDs = np.unique(imageIDs)\n",
    "treatments = np.array(image_feature_data['treatment'], dtype='object')\n",
    "Utreatments = np.unique(treatments)\n",
    "numMVperImg = np.array(image_feature_data['numMV'])\n",
    "\n",
    "numMV = image_feature_data.shape[1]-3\n",
    "mv_cols = columns[3:-4] #all columns corresponding to megavoxel categories #should usually be -5 since contrast is still included here.\n",
    "MV_freqs = image_feature_data[mv_cols].to_numpy()\n",
    "texture_cols = columns[-4:]\n",
    "# if rescale_texture_features:\n",
    "#     for i in range(len(texture_cols)):\n",
    "#         image_feature_data[texture_cols[i]] = clu.rescale(image_feature_data[texture_cols[i]], newmin=0, newmax=1)\n",
    "texture_data = image_feature_data[texture_cols].to_numpy()\n",
    "combined_cols = columns[3:]\n",
    "combined_data = image_feature_data[combined_cols].to_numpy()\n",
    "\n",
    "y = imageIDs\n",
    "z = treatments\n",
    "if datachoice.lower() == 'mv':\n",
    "    X = MV_freqs\n",
    "elif datachoice.lower() == 'text':\n",
    "    X = texture_data\n",
    "elif datachoice.lower() == 'combined':\n",
    "    X = combined_data\n",
    "else:\n",
    "    print('ERROR invalid data set choice.')\n",
    "print('Dataset shape:', X.shape, '\\n')\n",
    "\n",
    "print('Treatments found:')\n",
    "print(Utreatments)\n",
    "\n",
    "if len(Utreatments) > 10:\n",
    "    import matplotlib as mpl\n",
    "    colors = plt.cm.get_cmap('tab20')(np.linspace(0, 1, 20))\n",
    "    mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colors) \n",
    "\n",
    "from IPython.display import display\n",
    "# display(image_feature_data)\n",
    "display(image_feature_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sammon Mapping\n",
    "Make sammon map of Phindr3D data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot parameters: EDIT HERE\n",
    "title = 'Sammon map'\n",
    "xlabel = 'Axis 1'\n",
    "ylabel = 'Axis 2'\n",
    "\n",
    "S, E = clu.sammon(X, 2)\n",
    "print(S.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "for treat in Utreatments:\n",
    "    ax.scatter(S[z==treat, 0], S[z==treat, 1], label=treat)\n",
    "ax.legend()\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(xlabel)\n",
    "ax.set_ylabel(ylabel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA plot\n",
    "Make PCA plot of phindr3D results. currently uses kernel PCA with a variable function since it seems to get best results here. \n",
    "\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html for more information on types of PCA availble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA kernel function: EDIT HERE\n",
    "#set as 'linear' for linear PCA, 'rbf' for gaussian kernel, \n",
    "#'sigmoid' for sigmoid kernel, \n",
    "#'cosine' for cosine kernel\n",
    "func = 'rbf'\n",
    "\n",
    "#plot parameters: EDIT HERE\n",
    "title = 'PCA plot'\n",
    "xlabel = 'PCA 1'\n",
    "ylabel = 'PCA 2'\n",
    "\n",
    "#makes plot \n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_show = sc.fit_transform(X)\n",
    "pca = KernelPCA(n_components=2, kernel=func) \n",
    "P = pca.fit(X_show).transform(X_show)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for treat in Utreatments:\n",
    "    plt.scatter(P[z==treat, 0], P[z==treat, 1], label=treat)\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE\n",
    "\n",
    "Make t-SNE plot of phindr3D data. \n",
    "\n",
    "t-SNE is not a deterministic method, results may vary between different runs. Check https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html for additional parameters to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot parameters: EDIT HERE\n",
    "title = 't-SNE plot'\n",
    "xlabel = 'Axis 1'\n",
    "ylabel = 'Axis 2'\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "T = TSNE(n_components=2, init='pca', learning_rate='auto').fit_transform(X) #can edit here from tsne documentation.\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for treat in Utreatments:\n",
    "    plt.scatter(T[z==treat, 0], T[z==treat, 1], label=treat)\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AP clustering\n",
    "cluster phindr3D results into k clusters using affinity propagation. This process may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering parameters: EDIT HERE\n",
    "Nclusters = 7 #number of clusters to try to hit\n",
    "percent_dev = 1 #percentage by which final number of clusters may deviate from Nclusters\n",
    "\n",
    "\n",
    "#performs clustering\n",
    "C = clu.clsIn(X) #make similarity matrix\n",
    "idx, netsim, dpsim, expref, pref = clu.apclusterK(C.S, Nclusters, prc=percent_dev)\n",
    "clusters, counts = np.unique(idx, return_counts=True)\n",
    "print('\\n')\n",
    "for i in range(len(clusters)):\n",
    "    print(f'cluster{i+1}: {counts[i]} counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster rating\n",
    "Used mutual information scores to rate quality of clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z#treatments\n",
    "idx#which cluster\n",
    "treatlabels = np.zeros(z.shape)\n",
    "for i, t in enumerate(z):\n",
    "    treatlabels[z==t] = i+1\n",
    "\n",
    "print('Mutual information:', met.mutual_info_score(treatlabels, idx, ))\n",
    "print('Normalized mutual information:', met.normalized_mutual_info_score(treatlabels, idx))\n",
    "print('Adjusted mutual information:', met.adjusted_mutual_info_score(treatlabels, idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster visualization\n",
    "- Show clusters in reduced dimensionality plot\n",
    "- cluster pie charts\n",
    "- cluster heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize clusters\n",
    "\n",
    "#choose type of mapping: EDIT HERE\n",
    "#options: 'sammon', 'pca', 'tsne'\n",
    "map_type = 'sammon'\n",
    "\n",
    "#plot parameters: EDIT HERE\n",
    "title = 'Cluster map'\n",
    "xlabel = 'Axis 1'\n",
    "ylabel = 'Axis 2'\n",
    "\n",
    "\n",
    "if map_type.lower() == 'sammon':\n",
    "    show = S\n",
    "elif map_type.lower() == 'tsne':\n",
    "    show = T\n",
    "elif map_type.lower() == 'pca':\n",
    "    show = P\n",
    "#makes plot\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(len(clusters)):\n",
    "    plt.scatter(show[idx==clusters[i], 0], show[idx==clusters[i], 1], label=f'Cluster {i+1}')\n",
    "plt.legend()\n",
    "plt.title(title)\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make heatmap of cluster distribution for each treatment\n",
    "#plot parameters: EDIT HERE\n",
    "title = 'Cluster heatmap'\n",
    "xlabel = 'Cluster'\n",
    "ylabel = 'Treatment'\n",
    "\n",
    "# EDIT HERE: set ltreatment labels in desired output order\n",
    "orderedTreatments = [ 'example1', 'example2', 'example3', 'example4']\n",
    "\n",
    "map = np.zeros((len(orderedTreatments), len(clusters)))\n",
    "for i, treat in enumerate(orderedTreatments):\n",
    "    for j in range(len(clusters)):\n",
    "        map[i, j] = np.sum(np.logical_and(treatments==treat, idx==clusters[j]))\n",
    "\n",
    "#normalize the cluster counts for each treatment\n",
    "row_sum = np.sum(map, axis=1)\n",
    "map = map / row_sum[:, np.newaxis]\n",
    "map_bad = np.logical_not(np.isfinite(map)) #clean up any potential divide by 0 errors\n",
    "map[map_bad] = 0\n",
    "    \n",
    "#make plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(title)\n",
    "plt.imshow(map, cmap='plasma', aspect='auto')\n",
    "plt.xticks(ticks=[i for i in range(0, len(clusters))], labels=[f'{i}' for i in range(1, len(clusters)+1)])\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.yticks(ticks=[i for i in range(len(orderedTreatments))], labels=orderedTreatments)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make pie charts for each cluster\n",
    "#pie chart making is all automated, only need to run this cell.\n",
    "\n",
    "\n",
    "def percent(pct, allvals):\n",
    "    absolute = int(np.round(pct/100.*np.sum(allvals)))\n",
    "    return \"{:.1f}%\".format(pct, absolute)\n",
    "\n",
    "z = treatments\n",
    "\n",
    "for i in range(len(clusters)): \n",
    "    counts = np.zeros(len(Utreatments))\n",
    "    for j, treat in enumerate(Utreatments):\n",
    "        counts[j] = np.sum(np.logical_and(z==treat, idx==clusters[i]))\n",
    "    labels = Utreatments\n",
    "    fig, ax = plt.subplots(figsize=(15,8))\n",
    "    title = f'Cluster {i+1} composition ({round(np.sum(counts))} images)'\n",
    "    ax.set_title(title)\n",
    "    wedges, texts, autotexts = ax.pie(counts, labels=labels, autopct= lambda pct:percent(pct, counts))\n",
    "    ax.legend(wedges, labels, loc='center right', bbox_to_anchor=(0.8, 0.5, 0.5, 0.5))\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make heatmap of cluster distribution for each treatment\n",
    "#plot parameters: EDIT HERE\n",
    "title = 'Neuron cluster distribution'\n",
    "xlabel = 'Cluster'\n",
    "ylabel = 'Treatment'\n",
    "\n",
    "fclusters = np.delete(clusters, 2)\n",
    "\n",
    "map = np.zeros((len(Utreatments), len(fclusters)))\n",
    "for i, treat in enumerate(Utreatments):\n",
    "    for j in range(len(fclusters)):\n",
    "        map[i, j] = np.sum(np.logical_and(treatments==treat, idx==fclusters[j]))\n",
    "\n",
    "#normalize the cluster counts for each treatment\n",
    "row_sum = np.sum(map, axis=1)\n",
    "map = map / row_sum[:, np.newaxis]\n",
    "map_bad = np.logical_not(np.isfinite(map))\n",
    "map[map_bad] = 0\n",
    "\n",
    "    \n",
    "#make plot\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(title)\n",
    "plt.imshow(map, cmap='jet', aspect='auto')\n",
    "plt.xticks(ticks=[i for i in range(0, len(fclusters))], labels=[1,2,4,5])\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.yticks(ticks=[i for i in range(len(Utreatments))], labels=Utreatments)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72797a5196a82f4210641a973deeeaa51f5fd3a7d89b903b945becee6862e58f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('phy479': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
